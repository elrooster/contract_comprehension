
import boto3
import botocore
import time
import os
import os.path
import sys
import io
import urllib.parse
import json
import requests
import base64

from io import BytesIO
from requests_aws4auth import AWS4Auth
from opensearchpy import OpenSearch, RequestsHttpConnection
from s3transfer.manager import TransferManager
from trp import Document

print('commencing shenanigans')

### Global ###
region = 'us-east-1'
s3 = boto3.client('s3')
esClient = boto3.client('opensearch')
textract = boto3.client(service_name = 'textract', region_name = region)
comprehend = boto3.client(service_name = 'comprehend', region_name = region)
OutputBucket = 'doc-repository-002'
service = 'es'
host = 'https://search-contract-comprehension-4n2zfrqgqay6htz33yg7awiufi.us-east-1.es.amazonaws.com'
credentials = boto3.session().get_credentials()

### to-do... Add SNS so that progress may be tracked via SQS

#Connect to the opensearch domain
def connectES():
    print('connecting to the ES Endpoint {0}')
    awsauth = AWS4Auth(credentials.access-key,
    credentials.secret_key,
    region, service,
    session_token = credentials.token)

    try:
        es = OpenSearch(
            hosts = [{'host': host, 'port': 443}],
            http_auth = awsauth,
            use_ssl = True,
            verify_certs = True,
            connection_class = RequestsHttpConnection)
    return es

    except Exception as E:
        print('unable to connect to {0}')
        print(E)
        exit(3)

    print('success setting up opensearch')

def startJob(inputbucket, objectname):
    response = None
    response = textract.start_document_text_detection(
    DocumentLocation={
        'S3Object': {
            'Bucket': inputbucket,
            'Name': objectname
        }
    })

    return response['JobId']

def isJobComplete(jobid):
    time.sleep(5)
    response = textract.get_document_text_detection(JobId=jobid)
    status = response["JobStatus"]
    print("Job status: {}".format(status))

    while(status == "IN_PROGRESS"):
        time.sleep(5)
        response = textract.get_document_text_detection(JobId=jobid)
        status = response["JobStatus"]
        print("Job status: {}".format(status))

    return status

def getJobResults(jobid):
    pages = []
    time.sleep(5)
    response = textract.get_document_text_detection(JobId=jobid)
    pages.append(response)
    print("Resultset page recieved: {}".format(len(pages)))
    nextToken = None
    if('NextToken' in response):
        nextToken = response['NextToken']
    while(nextToken):
        time.sleep(5)
        response = textract.get_document_text_detection(JobId=jobid, NextToken=nextToken)
        pages.append(response)
        print("Resultset page recieved: {}".format(len(pages)))
        nextToken = None
        if('NextToken' in response):
            nextToken = response['NextToken']
    return pages

### not used - consider for later revision
#def outputForm(page):
#        csvData = []
#        for field in page.form.fields:
#            csvItem  = []
#            if(field.key):
#                csvItem.append(field.key.text)
#            else:
#                csvItem.append("")
#            if(field.value):
#                csvItem.append(field.value.text)
#            else:
#                csvItem.append("")
#            csvData.append(csvItem)
#        return csvData

### not used - consider how for pdf
#def outputTable(page):
#    csvData = []
#    print("//////////////////")
#    #print(page)
#    for table in page.tables:
#            csvRow = []
#            csvRow.append("Table")
#            csvData.append(csvRow)
#            for row in table.rows:
#                csvRow  = []
#                for cell in row.cells:
#                    csvRow.append(cell.text)
#                csvData.append(csvRow)
#            csvData.append([])
#            csvData.append([])
#    return csvData

### Not used... was trying to export blocks from textract as a textfile,
### could not get the formatting to work correctly. consider for future revision.
#def WriteToS3(textractdata, outputbucket, outputdocument):
#    FilePath = os.path.splitext(outputdocument)[0] + '.txt'
#    s3.put_object(Body = textractdata, Bucket = outputbucket, Key = FilePath)
#    print('regurgitated ' + generateFilePath)

### Main Lambda Handler ###
def lambda_handler(event, context):
    print('received event: ' + json.dumps(event, indent=2))

    # Get object from event, show content
    InputBucket = event['Records'][0]['s3']['bucket']['name']
    ObjectName = urllib.parse.unquote_plus(event['Records'][0]['s3']['object']['key'], encoding = 'utf-8')
    print('Object: ' + ObjectName)
    print('bucket: ' + InputBucket)
    text=''
    textvalues=[]
    textvalues_entity={}

    try:
        ### Textract
        JobId = startJob(InputBucket, ObjectName)
        print('starting job:'.format(JobId))
        if(isJobComplete(JobId)):
            response = getJobResults(JobId)
        #print(response)
        blocks=response['Blocks']
        for block in blocks:
            if block['BlockType'] == 'LINE':
                text += block['Text']+"\n"
        print(text)

        ### Comprehend
        keyphrase_response = comprehend.detect_key_phrases(Text=text, LanguageCode='en')
        KeyPhraseList=keyphrase_response.get("KeyPhrases")
        for s in KeyPhraseList:
              textvalues.append(s.get("Text"))

        detect_entity= comprehend.detect_entities(Text=text, LanguageCode='en')
        EntityList=detect_entity.get("Entities")
        for s in EntityList:
                textvalues_entity.update([(s.get("Type").strip('\t\n\r'),s.get("Text").strip('\t\n\r'))])

        s3url = 'https://s3.console.aws.amazon.com/s3/object/'+InputBucket+'/'+ObjectName+'?region= '+ region

        ### Consider Tables and Forms later
        searchdata = {'s3link': s3url, 'KeyPhrases': textvalues, 'Entity':textvalues_entity, 'text': text}
        print(searchdata)
        print('connecting to opensearch')
        es = connectES()
        es.index(index = 'document', doc_type = '_doc', body = searchable)
        print('data uploaded to opensearch')
        return 'victory?'

        #WriteToS3(response, OutputBucket, ObjectName)

    except Exception as e:
        print(e)
        print('Error getting object {} from bucket {}')
        raise e
