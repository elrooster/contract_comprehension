import boto3
import botocore
import json
import urllib.parse
import time

from s3transfer.manager import TransferManager
#from trp import Document

print('commencing shenanigans')

### Global ###
region = 'us-east-1'
s3 = boto3.client('s3')
textract = boto3.client(service_name = 'textract', region_name = region)
InputBucket = 'doc-repository-001'
OutputBucket = 'doc-repository-002'

### Textract: Start Async Job
def startJob(inputbucket, objectname):
    response = None
    response = textract.start_document_text_detection(
    DocumentLocation={
        'S3Object': {
            'Bucket': inputbucket,
            'Name': objectname
        }
    })

    return response['JobId']

### Textract: Check job
def isJobComplete(jobid):
    time.sleep(5)
    response = textract.get_document_text_detection(JobId=jobid)
    status = response["JobStatus"]
    print("Job status: {}".format(status))

    while(status == "IN_PROGRESS"):
        time.sleep(5)
        response = textract.get_document_text_detection(JobId=jobid)
        status = response["JobStatus"]
        print("Job status: {}".format(status))

    return status

### Textract: Get job
def getJobResults(jobid):
    pages = []
    time.sleep(5)
    response = textract.get_document_text_detection(JobId=jobid)
    pages.append(response)
    print("Resultset page recieved: {}".format(len(pages)))
    nextToken = None
    if('NextToken' in response):
        nextToken = response['NextToken']
    while(nextToken):
        time.sleep(5)
        response = textract.get_document_text_detection(JobId=jobid, NextToken=nextToken)
        pages.append(response)
        print("Resultset page recieved: {}".format(len(pages)))
        nextToken = None
        if('NextToken' in response):
            nextToken = response['NextToken']
    return pages

#################################################################
def lambda_handler(event, context):
    print('received event: ' + json.dumps(event, indent=2))

    # Get object from event, show content
    InputBucket = event['Records'][0]['s3']['bucket']['name']
    ObjectName = urllib.parse.unquote_plus(event['Records'][0]['s3']['object']['key'], encoding = 'utf-8')
    s3Uri = 's3://'+InputBucket+'/'+ObjectName
    print('Object Name: ' + ObjectName)
    print('Input Bucket: ' + InputBucket)
    print('s3URI: '+ s3Uri)

    textvalues=[]
    textvalues_entity={}

    try:
        print(s3Uri)
        JobId = startJob(InputBucket, ObjectName)
        print('Job Started')

        #loop until job complete
        if(isJobComplete(JobId)):
            response = getJobResults(JobId)

        #get text blocks
        #blocks = response['Blocks']


        #save json response from textract into s3
        raw_textract = s3.put_object(
            Bucket = OutputBucket,
            Key = ObjectName + '-RAW.json',
            Body = json.dumps(response)
        )
        print(f'Textracted: {OutputBucket}/{ObjectName}.json')

        #recreate text from textract Output

        #for block in blocks:
        #    if (block['BlockType'] == 'LINE'):
        #        text += block['Text'] + '\n '
        text=''
        for result in response:
            for block in result["Blocks"]:
                if block["BlockType"] == "LINE":
                    text += block['Text'] + " "

        #put text file into bucket
        txt_textract = s3.put_object(
            Bucket = OutputBucket,
            Key = ObjectName + '-TEXT.txt',
            Body = json.dumps(text)
        )
        print(f'Text file created: {OutputBucket}/{ObjectName}.txt')


    except Exception as e:
        print(e)
        print('Error getting object {} from bucket {}')
        raise e
