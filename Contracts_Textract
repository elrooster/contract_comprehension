import boto3
import botocore
import time
import os
import os.path
import sys
import io
import urllib.parse
import json
import requests
import base64

from io import BytesIO
from requests_aws4auth import AWS4Auth
from opensearchpy import OpenSearch, RequestsHttpConnection
from s3transfer.manager import TransferManager
from trp import Document
from s3transfer.manager import TransferManager
from trp import Document

print('commencing shenanigans')

### Global ###
region = 'us-east-1'
s3 = boto3.client('s3')
textract = boto3.client(service_name = 'textract', region_name = region)
InputBucket = 'doc-repository-001'
OutputBucket = 'doc-repository-002'
osClient = boto3.client('opensearch')
service = 'es'
host = 'search-document-search-ssbjzd4kon2gajx7wrs5pc7nm4.us-east-1.es.amazonaws.com/'
credentials = boto3.Session().get_credentials()

### Connect to the opensearch domain
def connectOS():
    print('connecting to the OS Endpoint {0}')
    awsauth = AWS4Auth(credentials.access_key,
    credentials.secret_key,
    region, service,
    session_token = credentials.token)
    print(awsauth)

    try:
        es = OpenSearch(
            hosts = [{'host': host, 'port': 443}],
            http_auth = awsauth,
            use_ssl = True,
            verify_certs = True,
            connection_class = RequestsHttpConnection)
        return es

    except Exception as E:
        print('unable to connect to {0}')
        print(E)
        exit(3)



### Textract: Start Async Job
def startJob(inputbucket, objectname):
    response = None
    response = textract.start_document_text_detection(
    DocumentLocation={
        'S3Object': {
            'Bucket': inputbucket,
            'Name': objectname
        }
    })

    return response['JobId']

### Textract: Check job
def isJobComplete(jobid):
    time.sleep(5)
    response = textract.get_document_text_detection(JobId=jobid)
    status = response["JobStatus"]
    print("Job status: {}".format(status))

    while(status == "IN_PROGRESS"):
        time.sleep(5)
        response = textract.get_document_text_detection(JobId=jobid)
        status = response["JobStatus"]
        print("Job status: {}".format(status))

    return status

### Textract: Get job
def getJobResults(jobid):
    pages = []
    time.sleep(5)
    response = textract.get_document_text_detection(JobId=jobid)
    pages.append(response)
    print("Resultset page recieved: {}".format(len(pages)))
    nextToken = None
    if('NextToken' in response):
        nextToken = response['NextToken']
    while(nextToken):
        time.sleep(5)
        response = textract.get_document_text_detection(JobId=jobid, NextToken=nextToken)
        pages.append(response)
        print("Resultset page recieved: {}".format(len(pages)))
        nextToken = None
        if('NextToken' in response):
            nextToken = response['NextToken']
    return pages

#################################################################
def lambda_handler(event, context):
    print('received event: ' + json.dumps(event, indent=2))

    # Get object from event, show content
    InputBucket = event['Records'][0]['s3']['bucket']['name']
    ObjectName = urllib.parse.unquote_plus(event['Records'][0]['s3']['object']['key'], encoding = 'utf-8')
    s3Uri = 's3://'+InputBucket+'/'+ObjectName
    print('Object Name: ' + ObjectName)
    print('Input Bucket: ' + InputBucket)
    print('s3URI: '+ s3Uri)

    try:
        print(s3Uri)
        JobId = startJob(InputBucket, ObjectName)
        print('Job Started')

        #loop until job complete
        if(isJobComplete(JobId)):
            response = getJobResults(JobId)

        #save json response from textract into s3
        #raw_textract = s3.put_object(
        #    Bucket = OutputBucket,
        #    Key = '/json/' + ObjectName + '-RAW.json',
        #    Body = json.dumps(response)
        #)
        #print(f'Textracted: {OutputBucket}/{ObjectName}.json')

        #recreate text from textract Output
        text=''
        for result in response:
            for block in result["Blocks"]:
                if block["BlockType"] == "LINE":
                    text += block['Text'] + " "

        #save text file into bucket
        #txt_textract = s3.put_object(
        #    Bucket = OutputBucket,
        #    Key = '/txt/' + ObjectName + '-TEXT.txt',
        #    Body = json.dumps(text)
        #)
        #print(f'Text file created: {OutputBucket}/{ObjectName}.txt')

        s3url = 'https://s3.console.aws.amazon.com/s3/object/'+InputBucket+'/'+ObjectName+'?region='+ region

        ### Write to OpenSearch
        searchdata = {'s3link': s3url, 'text': text}
        print(searchdata)
        print('connecting to opensearch')
        es = connectOS()
        es.index(index = 'document', doc_type = '_doc', body = searchdata)
        print('data uploaded to opensearch')
        return 'victory?'

    except Exception as e:
        print(e)
        print('Error getting object {} from bucket {}')
        raise e
